{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Methods in Economics\n",
    "\n",
    "## Problem Set 5 - Numerical Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2018-12-05 14:19:25.539797\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (N)\n",
    "\n",
    "*From Judd(1998), chapter 4, question 2*. One of the classical uses of optimization is the computation of the *Pareto frontier*. Consider the endowment economy with $m$ goods and $n$ agents. Assume that agent $i$'s utility function over the $m$ goods is \n",
    "\n",
    "\\begin{equation}\n",
    "    u^{i}(x^i) = \\sum^{m}_{j = 1} a^i_j (x^i_j)^{v^i_j + 1} (1 + v^i_j)^{-1} \n",
    "\\end{equation}\n",
    "\n",
    "Suppose that agent $i$'s endowment of good $j$ is $e^i_j$. Assume that $a^i_j, e^i_j > 0 > v^i_j$ (for $v^i_j$, we replace $(x^i_j)^{v^i_j + 1} (1 + v^i_j)^{-1}$ with $\\ln x^i_j$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Write a program using Scipy's BFGS implementation that will read in the $v^i_j$, $a^i_j$ and $e^i_j$ and the social weights $\\lambda^i$, and output the solution to the social planner's problem. Choose $m = n = 2$ and solve the problem *analytically* for $\\lambda_1 = \\lambda_2 = 0.5$ and the following values for the remaining parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = [[-4 -2]\n",
      " [-3 -3]]\n",
      "A = [[1 4]\n",
      " [1 8]]\n",
      "E = [[6 4]\n",
      " [5 1]]\n"
     ]
    }
   ],
   "source": [
    "E = np.array([[6, 4], [5, 1]])\n",
    "V = np.array([[-4, -2], [-3, -3]])\n",
    "A = np.array([[1, 4], [1, 8]])\n",
    "\n",
    "print(\"V = {}\".format(V) )\n",
    "print(\"A = {}\".format(A) )\n",
    "print(\"E = {}\".format(E) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to read these matrices is that a good corresponds to a row and an agent to a column. For example, agent 1's endowment of good 2, $e^1_2$, would be the element in the second row and first column of matrix **E**, and hence $e^1_2 = 5$.\n",
    "\n",
    "With these parameter values, confirm that your analytical result equals the numerical output of your program. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Test your program for higher numbers of goods and agents. You can create the parameter matrices above using Numpy's **np.random.uniform** function. Can your program handle $m = n = 5$? $m = n = 10$?      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: A slightly tricky issue when answering this question using *unconstrained* numerical optimization methods is how to deal with the constraint that aggregate consumption of good $j$ must equal aggregate endowments, i.e.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum^{n}_{i = 1} x_j^i = \\sum^{n}_{i = 1} e_j^i\n",
    "\\end{equation}\n",
    "\n",
    "One way to address this is to have the algorithm solve for the optimal consumption for $n - 1$ agents and evaluate the consumption and hence the utility of the last agent *as the residual*. Formally, for good $j$,\n",
    "\n",
    "\\begin{equation}\n",
    "    x_j^n = \\sum^{n}_{i = 1} e_j^i - \\sum^{n-1}_{i = 1} x_j^i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (N)\n",
    "\n",
    "Consider the neoclassical growth model from the lecture. In this question, we extend it so that the production function contains *energy* $m_t$ as a third production factor in addition to capital and labor. Hence, output is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    y_t = f(k_t, h_{y,t}, m_t) = A k_t^\\alpha m_t^\\gamma h_{y,t}^{1-\\alpha-\\gamma}\n",
    "\\end{equation}\n",
    "\n",
    "Energy is itself produced by using a part of the labor supply:\n",
    "\n",
    "\\begin{equation}\n",
    "    m_t = \\rho h_{m,t}\n",
    "\\end{equation}\n",
    "\n",
    "which implies that one unit of labor supply creates $\\rho$ units of energy.\n",
    "\n",
    "Solve the planner problem numerically for $T = 30$. Note that lifetime utility is still given by \n",
    "\n",
    "\\begin{equation}\n",
    "    u(c_t, h_t) = \\frac{c^{1-\\nu}}{1-\\nu} - B \\frac{h_t^{1+\\eta}}{1+\\eta}\n",
    "\\end{equation}\n",
    "\n",
    "with $h_t = h_{y,t} + h_{m,t}$. You can use the parameter values from the lecture, and $\\gamma = 0.05$ and $\\rho = 0.9$. \n",
    "\n",
    "In addition, compute the steady state using a root finding algorithm and verify that the planner's sequences for $k_t$, $h_{y,t}$ and $h_{m,t}$ converge to their steady state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3 (A)\n",
    "\n",
    "Show that for an arbitrary $m$-by-$n$ matrix $A$ with $m \\ge n$ and rank $n$ - i.e., that has linearly independent columns - the matrix product $A^T A$ is positive definite and symmetric. Recall that a square matrix $B$ of order $n$ is *positive definite* if there is a positive scalar such that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{x}^T B x \\ge \\alpha \\mathbf{x}^T \\mathbf{x} \\quad \\text{for all} \\quad \\mathbf{x} \\in \\mathbb{R}^n.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 4 (N)\n",
    "\n",
    "Use gradient descent to solve the monopoly example from lecture 5a, which is summarized in the cells below. That is, define a **step** function for gradient descent that can be used use in the **my_opt** routine, also given below. The distance $\\alpha$ should be fixed for a given run of the algorithm, but you can play around with different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### functions and parameters\n",
    "alpha = 0.98\n",
    "eta = 0.85\n",
    "\n",
    "cy = 0.62\n",
    "cz = 0.6\n",
    "\n",
    "Cy = lambda x : cy * x\n",
    "Cz = lambda x : cz * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def u(Y, Z):\n",
    "    \"\"\"\n",
    "    Returns the u function.\n",
    "    \"\"\"\n",
    "    return (Y**alpha + Z**alpha)**(eta/alpha)\n",
    "\n",
    "def ud(Y, Z):\n",
    "    \"\"\"\n",
    "    Returns the derivative of the u function.\n",
    "    \"\"\"\n",
    "    return eta * (Y**alpha + Z**alpha)**(eta/alpha - 1) * Y**(alpha - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def obj(x):\n",
    "    \"\"\"\n",
    "    Implements the objective function (here profit) for the monopoly example: Y * ud(Y, Z) + Z * ud(Z, Y) - Cy(Y) - Cz(Z)\n",
    "    \"\"\"\n",
    "    Y = np.exp(x[0])\n",
    "    Z = np.exp(x[1])\n",
    "    \n",
    "    return - (Y * ud(Y, Z) + Z * ud(Z, Y) - Cy(Y) - Cz(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_opt(x, obj, step, maxit = 100, eps = 1e-8, delta = 1e-4):\n",
    "    \"\"\"\n",
    "    Implements the iterative procedure for all of the optimization algorithms considered below. \n",
    "    Mandatory inputs are \n",
    "    -> x: initial guess for the minimizing vector\n",
    "    -> obj: objective, defined a function of x\n",
    "    -> step: a function implementing how the step from x(k) to x(k+1) is determined\n",
    "    \"\"\"\n",
    "    dist = 1\n",
    "    it = 0\n",
    "    \n",
    "    lx = []\n",
    "    while dist > eps and it < maxit:\n",
    "        lx.append(x)\n",
    "        it += 1\n",
    "    \n",
    "        s, alpha = step(x, obj)\n",
    "    \n",
    "        dist = np.linalg.norm(s) / (1 + np.linalg.norm(x))\n",
    "        print(it, dist, alpha)\n",
    "        x = x + s\n",
    "    \n",
    "    ## check for optimality\n",
    "    gr = sm.tools.numdiff.approx_fprime(x, obj)\n",
    "    if np.linalg.norm(gr) > delta * (1 + abs(obj(x))):\n",
    "        print('Solution does not appear an optimum!')\n",
    "    \n",
    "    return x, lx  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (N)\n",
    "\n",
    "In this question, we are going to apply the gradient descent minimization algorithm on a least-squares regression problem. Consider the Bundesliga data set used in the *Introduction to Python* section of this class. Let's assume we would like to regress a player's market value on his age, his number of goals and assists. Running the following cell (i) reads in the relevant columns of the data set; (ii) creates a matrix X with the explanatory variables; and (iii) creates an array y containing the dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'value')\n",
      "(4, 'age')\n",
      "(5, 'goals')\n",
      "(6, 'assists')\n",
      "(291, 3)\n",
      "(291, 1)\n",
      "[[28. 30.  4.]\n",
      " [27. 29.  2.]\n",
      " [27.  5. 12.]\n",
      " [27.  5.  4.]\n",
      " [26.  4.  3.]\n",
      " [20.  6. 11.]\n",
      " [26.  2.  2.]\n",
      " [28. 10.  2.]\n",
      " [20.  2.  1.]\n",
      " [20.  2.  1.]]\n"
     ]
    }
   ],
   "source": [
    "cols=(2,4,5,6)\n",
    "D = np.loadtxt('BundesligaData.txt', delimiter=';',usecols=(cols), skiprows=1)\n",
    "D[:10, :]\n",
    "\n",
    "description = ['name', 'position', 'value', 'valuemax', 'age', 'goals','assists', 'yellow', 'red', 'shotspergame','passsuccess','aerialswon', 'rating', 'positioncode']\n",
    "for i in cols:\n",
    "    print((i,description[i]))\n",
    "\n",
    "X = D[:,1:]\n",
    "## dependent variable\n",
    "y = D[:,0] \n",
    "y.shape=(D.shape[0], 1)\n",
    "# Before regressing the values, we should check whether X and y have the right shape\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X[:10, :])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Scale the values in **X** and add a column of ones. \n",
    "\n",
    "(b) For comparison, use the normal equation to compute $\\mathbf{b}$.\n",
    "\n",
    "(c) Implement the gradient descent algorithm outlined above to find $\\mathbf{b}$. Assume that the step size $\\alpha$ is constant. You may have to play around with $\\alpha$ to find a value that gives you convergence. *Hint*: Recall that in the context of gradient descent, convergence may be slow. When implementing the algorithm above with a **while** loop, you should (as we always do) include a condition that the loop stops after a certain number of iterations, **maxit**. Make sure to set **maxit** sufficiently high in order to get convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
